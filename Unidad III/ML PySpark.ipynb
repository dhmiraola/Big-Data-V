{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1235473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+------+----------+-----------------+-----------------+----------------+--------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|         Name|Age|Gender|Blood Type|Medical Condition|Date of Admission|          Doctor|            Hospital|Insurance Provider|    Billing Amount|Room Number|Admission Type|Discharge Date| Medication|Test Results|\n",
      "+-------------+---+------+----------+-----------------+-----------------+----------------+--------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "|Bobby JacksOn| 30|  Male|        B-|           Cancer|       2024-01-31|   Matthew Smith|     Sons and Miller|        Blue Cross|18856.281305978155|        328|        Urgent|    2024-02-02|Paracetamol|      Normal|\n",
      "| LesLie TErRy| 62|  Male|        A+|          Obesity|       2019-08-20| Samantha Davies|             Kim Inc|          Medicare|33643.327286577885|        265|     Emergency|    2019-08-26|  Ibuprofen|Inconclusive|\n",
      "|  DaNnY sMitH| 76|Female|        A-|          Obesity|       2022-09-22|Tiffany Mitchell|            Cook PLC|             Aetna|27955.096078842456|        205|     Emergency|    2022-10-07|    Aspirin|      Normal|\n",
      "| andrEw waTtS| 28|Female|        O+|         Diabetes|       2020-11-18|     Kevin Wells|Hernandez Rogers ...|          Medicare| 37909.78240987528|        450|      Elective|    2020-12-18|  Ibuprofen|    Abnormal|\n",
      "|adrIENNE bEll| 43|Female|       AB+|           Cancer|       2022-09-19|  Kathleen Hanna|         White-White|             Aetna|14238.317813937623|        458|        Urgent|    2022-10-09| Penicillin|    Abnormal|\n",
      "+-------------+---+------+----------+-----------------+-----------------+----------------+--------------------+------------------+------------------+-----------+--------------+--------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Blood Type: string (nullable = true)\n",
      " |-- Medical Condition: string (nullable = true)\n",
      " |-- Date of Admission: date (nullable = true)\n",
      " |-- Doctor: string (nullable = true)\n",
      " |-- Hospital: string (nullable = true)\n",
      " |-- Insurance Provider: string (nullable = true)\n",
      " |-- Billing Amount: double (nullable = true)\n",
      " |-- Room Number: integer (nullable = true)\n",
      " |-- Admission Type: string (nullable = true)\n",
      " |-- Discharge Date: date (nullable = true)\n",
      " |-- Medication: string (nullable = true)\n",
      " |-- Test Results: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesi√≥n de Spark\n",
    "spark = SparkSession.builder.appName(\"HealthcareClassification\").getOrCreate()\n",
    "\n",
    "# Cargar el dataset\n",
    "df = spark.read.csv(\"healthcare_dataset.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "df.show(5)\n",
    "\n",
    "# Verificar el esquema\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b29e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimunar columnas que no aportan al modelo\n",
    "df = df.drop(\"Name\", \"Doctor\", \"Hospital\", \"Room Number\", \"Date of Admission\", \"Discharge Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bfb0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+-----------------+------------------+--------------+--------------+----------+------------+\n",
      "|Age|Gender|Blood Type|Medical Condition|Insurance Provider|Billing Amount|Admission Type|Medication|Test Results|\n",
      "+---+------+----------+-----------------+------------------+--------------+--------------+----------+------------+\n",
      "|  0|     0|         0|                0|                 0|             0|             0|         0|           0|\n",
      "+---+------+----------+-----------------+------------------+--------------+--------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Lista de columnas\n",
    "columnas = df.columns\n",
    "\n",
    "# Conteo de nulos por columna\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in columnas]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b53d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de que existan valores perdidos\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6508048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexar variables categoricas\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "categorical_cols = [\"Gender\", \"Blood Type\", \"Medical Condition\", \"Insurance Provider\", \"Admission Type\", \"Medication\", \"Test Results\"]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c + \"_index\") for c in categorical_cols]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2696a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 1. USAR LOS NOMBRES EXACTOS, tal como aparecen en el DataFrame\n",
    "feature_cols = [\n",
    "    \"Age\", \"Billing Amount\",\n",
    "    \"Gender_index\", \"Blood Type_index\", \"Medical Condition_index\",\n",
    "    \"Insurance Provider_index\", \"Admission Type_index\", \"Medication_index\"\n",
    "]\n",
    "\n",
    "# 2. VectorAssembler \n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# 3. Definir label (Test Results)\n",
    "df = df.select(\"features\", col(\"Test Results_index\").alias(\"label\"))\n",
    "\n",
    "# 4. Divisi√≥n entrenamiento / prueba\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 5. Entrenar modelo\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=50)\n",
    "rf_model = rf.fit(train_data)\n",
    "rf_pred = rf_model.transform(test_data)\n",
    "\n",
    "# 6. Funciones para m√©tricas y matriz de confusi√≥n\n",
    "def evaluar_modelo(pred_df, nombre_modelo):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    \n",
    "    acc = evaluator.evaluate(pred_df, {evaluator.metricName: \"accuracy\"})\n",
    "    prec = evaluator.evaluate(pred_df, {evaluator.metricName: \"weightedPrecision\"})\n",
    "    rec = evaluator.evaluate(pred_df, {evaluator.metricName: \"weightedRecall\"})\n",
    "    f1 = evaluator.evaluate(pred_df, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "    print(f\"\\nüìä Resultados para {nombre_modelo}:\")\n",
    "    print(f\"Accuracy  : {acc:.3f}\")\n",
    "    print(f\"Precision : {prec:.3f}\")\n",
    "    print(f\"Recall    : {rec:.3f}\")\n",
    "    print(f\"F1-score  : {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d5814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf27c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91acd78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b103948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
