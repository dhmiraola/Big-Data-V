{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ffda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una sesi√≥n de Spark\n",
    "spark = SparkSession.builder.appName(\"TitanicML\").getOrCreate()\n",
    "\n",
    "# Cargar el dataset CSV\n",
    "df = spark.read.csv(\"titanic3.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fa324",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e73133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+------+------+-----+-----+------+--------+-------+--------+----+----+--------------------+\n",
      "|pclass|survived|                name|   sex|   age|sibsp|parch|ticket|    fare|  cabin|embarked|boat|body|           home.dest|\n",
      "+------+--------+--------------------+------+------+-----+-----+------+--------+-------+--------+----+----+--------------------+\n",
      "|     1|       1|Allen, Miss. Elis...|female|  29.0|    0|    0| 24160|211.3375|     B5|       S|   2|NULL|        St Louis, MO|\n",
      "|     1|       1|Allison, Master. ...|  male|0.9167|    1|    2|113781|  151.55|C22 C26|       S|  11|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Miss. He...|female|   2.0|    1|    2|113781|  151.55|C22 C26|       S|NULL|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Mr. Huds...|  male|  30.0|    1|    2|113781|  151.55|C22 C26|       S|NULL| 135|Montreal, PQ / Ch...|\n",
      "|     1|       0|Allison, Mrs. Hud...|female|  25.0|    1|    2|113781|  151.55|C22 C26|       S|NULL|NULL|Montreal, PQ / Ch...|\n",
      "+------+--------+--------------------+------+------+-----+-----+------+--------+-------+--------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899cdb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: integer (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: integer (nullable = true)\n",
      " |-- home.dest: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Esquema del DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb3da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+-----+-----+--------+--------+----+----+--------------------+\n",
      "|pclass|survived|   sex|   age|sibsp|parch|    fare|embarked|boat|body|           home.dest|\n",
      "+------+--------+------+------+-----+-----+--------+--------+----+----+--------------------+\n",
      "|     1|       1|female|  29.0|    0|    0|211.3375|       S|   2|NULL|        St Louis, MO|\n",
      "|     1|       1|  male|0.9167|    1|    2|  151.55|       S|  11|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       0|female|   2.0|    1|    2|  151.55|       S|NULL|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       0|  male|  30.0|    1|    2|  151.55|       S|NULL| 135|Montreal, PQ / Ch...|\n",
      "|     1|       0|female|  25.0|    1|    2|  151.55|       S|NULL|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       1|  male|  48.0|    0|    0|   26.55|       S|   3|NULL|        New York, NY|\n",
      "|     1|       1|female|  63.0|    1|    0| 77.9583|       S|  10|NULL|          Hudson, NY|\n",
      "|     1|       0|  male|  39.0|    0|    0|     0.0|       S|NULL|NULL|         Belfast, NI|\n",
      "|     1|       1|female|  53.0|    2|    0| 51.4792|       S|   D|NULL| Bayside, Queens, NY|\n",
      "|     1|       0|  male|  71.0|    0|    0| 49.5042|       C|NULL|  22| Montevideo, Uruguay|\n",
      "|     1|       0|  male|  47.0|    1|    0| 227.525|       C|NULL| 124|        New York, NY|\n",
      "|     1|       1|female|  18.0|    1|    0| 227.525|       C|   4|NULL|        New York, NY|\n",
      "|     1|       1|female|  24.0|    0|    0|    69.3|       C|   9|NULL|       Paris, France|\n",
      "|     1|       1|female|  26.0|    0|    0|   78.85|       S|   6|NULL|                NULL|\n",
      "|     1|       1|  male|  80.0|    0|    0|    30.0|       S|   B|NULL|       Hessle, Yorks|\n",
      "|     1|       0|  male|  NULL|    0|    0|  25.925|       S|NULL|NULL|        New York, NY|\n",
      "|     1|       0|  male|  24.0|    0|    1|247.5208|       C|NULL|NULL|        Montreal, PQ|\n",
      "|     1|       1|female|  50.0|    0|    1|247.5208|       C|   6|NULL|        Montreal, PQ|\n",
      "|     1|       1|female|  32.0|    0|    0| 76.2917|       C|   8|NULL|                NULL|\n",
      "|     1|       0|  male|  36.0|    0|    0| 75.2417|       C|   A|NULL|        Winnipeg, MN|\n",
      "+------+--------+------+------+-----+-----+--------+--------+----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Eliminar columnas irrelevantes\n",
    "df = df.drop(\"Name\", \"Ticket\", \"Cabin\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f85fbf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+-----+-----+--------+--------+----+----+--------------------+\n",
      "|pclass|survived|   sex|   age|sibsp|parch|    fare|embarked|boat|body|           home_dest|\n",
      "+------+--------+------+------+-----+-----+--------+--------+----+----+--------------------+\n",
      "|     1|       1|female|  29.0|    0|    0|211.3375|       S|   2|NULL|        St Louis, MO|\n",
      "|     1|       1|  male|0.9167|    1|    2|  151.55|       S|  11|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       0|female|   2.0|    1|    2|  151.55|       S|NULL|NULL|Montreal, PQ / Ch...|\n",
      "|     1|       0|  male|  30.0|    1|    2|  151.55|       S|NULL| 135|Montreal, PQ / Ch...|\n",
      "|     1|       0|female|  25.0|    1|    2|  151.55|       S|NULL|NULL|Montreal, PQ / Ch...|\n",
      "+------+--------+------+------+-----+-----+--------+--------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columnas \n",
    "df = df.withColumnRenamed(\"home.dest\", \"home_dest\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17abff1",
   "metadata": {},
   "source": [
    "# Imputar valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b3eaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+---+-----+-----+----+--------+----+----+---------+\n",
      "|pclass|survived|sex|age|sibsp|parch|fare|embarked|boat|body|home_dest|\n",
      "+------+--------+---+---+-----+-----+----+--------+----+----+---------+\n",
      "|     0|       0|  0|263|    0|    0|   1|       2| 823|1188|      564|\n",
      "+------+--------+---+---+-----+-----+----+--------+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conteo de valores nulos por columna\n",
    "from pyspark.sql.functions import col, sum as sum_\n",
    "\n",
    "df.select([sum_(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c49516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar por la Mediana\n",
    "\n",
    "from pyspark.sql.functions import col, when, mean, percentile_approx\n",
    "# Mediana de \"age\"\n",
    "mediana_age = df.select(percentile_approx(\"age\", 0.5)).first()[0]\n",
    "# Imputar valores nulos en \"age\"\n",
    "df = df.withColumn(\"age\", when(col(\"age\").isNull(), mediana_age).otherwise(col(\"age\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec22732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar por la Media o Promedio\n",
    "\n",
    "# Media de \"fare\"\n",
    "media_fare = df.select(mean(col(\"fare\"))).first()[0]\n",
    "df = df.withColumn(\"fare\", when(col(\"fare\").isNull(), media_fare).otherwise(col(\"fare\")))\n",
    "\n",
    "# Media de \"body\"\n",
    "media_body = df.select(mean(col(\"body\"))).first()[0]\n",
    "df = df.withColumn(\"body\", when(col(\"body\").isNull(), media_body).otherwise(col(\"body\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ef8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar columna 'object'\n",
    "\n",
    "# Imputar \"Sin Informacion\" en \"embarked\"\n",
    "df = df.withColumn(\"embarked\", when(col(\"embarked\").isNull(), \"Sin Informacion\").otherwise(col(\"embarked\")))\n",
    "\n",
    "# Imputar \"Sin Informacion\" en \"home_dest\"\n",
    "df = df.withColumn(\"home_dest\", when(col(\"home_dest\").isNull(), \"Sin Informacion\").otherwise(col(\"home_dest\")))\n",
    "\n",
    "# Imputar \"Sin Informacion\" en \"boat\"\n",
    "df = df.withColumn(\"boat\", when(col(\"boat\").isNull(), \"Sin Informacion\").otherwise(col(\"boat\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d9be70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+---+-----+-----+----+--------+----+----+---------+\n",
      "|pclass|survived|sex|age|sibsp|parch|fare|embarked|boat|body|home_dest|\n",
      "+------+--------+---+---+-----+-----+----+--------+----+----+---------+\n",
      "|     0|       0|  0|  0|    0|    0|   0|       0|   0|   0|        0|\n",
      "+------+--------+---+---+-----+-----+----+--------+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores NaN\n",
    "from pyspark.sql.functions import col, sum as sum_\n",
    "\n",
    "df.select([sum_(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b59467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pclass: integer (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: double (nullable = true)\n",
      " |-- home_dest: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Esquema del DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fd9240",
   "metadata": {},
   "source": [
    "# Separar variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ba9e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contar cu√°ntos valores √∫nicos hay en \"embarked\"\n",
    "df.select(\"embarked\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943577d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"boat\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45033e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"home_dest\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5caebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"boat\", \"home_dest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4e916e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+-----+-----+--------+--------+-----------------+\n",
      "|pclass|survived|   sex|   age|sibsp|parch|    fare|embarked|             body|\n",
      "+------+--------+------+------+-----+-----+--------+--------+-----------------+\n",
      "|     1|       1|female|  29.0|    0|    0|211.3375|       S|160.8099173553719|\n",
      "|     1|       1|  male|0.9167|    1|    2|  151.55|       S|160.8099173553719|\n",
      "|     1|       0|female|   2.0|    1|    2|  151.55|       S|160.8099173553719|\n",
      "|     1|       0|  male|  30.0|    1|    2|  151.55|       S|            135.0|\n",
      "|     1|       0|female|  25.0|    1|    2|  151.55|       S|160.8099173553719|\n",
      "+------+--------+------+------+-----+-----+--------+--------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "033c6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fc6b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexar la columna \"embarked\"\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Indexar la columna \"embarked\" correctamente\n",
    "indexer_embarked = StringIndexer(inputCol=\"embarked\", outputCol=\"embarked_index\")\n",
    "df = indexer_embarked.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ab80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexar la columna \"embarked\"\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Indexar la columna \"embarked\" correctamente\n",
    "indexer_embarked = StringIndexer(inputCol=\"sex\", outputCol=\"sex_index\")\n",
    "df = indexer_embarked.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc970e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+------+-----+-----+--------+--------+-----------------+--------------+---------+\n",
      "|pclass|survived|   sex|   age|sibsp|parch|    fare|embarked|             body|embarked_index|sex_index|\n",
      "+------+--------+------+------+-----+-----+--------+--------+-----------------+--------------+---------+\n",
      "|     1|       1|female|  29.0|    0|    0|211.3375|       S|160.8099173553719|           0.0|      1.0|\n",
      "|     1|       1|  male|0.9167|    1|    2|  151.55|       S|160.8099173553719|           0.0|      0.0|\n",
      "|     1|       0|female|   2.0|    1|    2|  151.55|       S|160.8099173553719|           0.0|      1.0|\n",
      "|     1|       0|  male|  30.0|    1|    2|  151.55|       S|            135.0|           0.0|      0.0|\n",
      "|     1|       0|female|  25.0|    1|    2|  151.55|       S|160.8099173553719|           0.0|      1.0|\n",
      "+------+--------+------+------+-----+-----+--------+--------+-----------------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3f15917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1. Definir las columnas que ser√°n features o independientes o predictoras (X)\n",
    "feature_cols = [\"pclass\", \"sex_index\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked_index\", \"body\"]\n",
    "\n",
    "# 2. Usar VectorAssembler para juntar las features en una sola columna\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "# 3. Seleccionar solamente features + label que es la variable dependiente u objetivo (y)\n",
    "df = df.select(\"features\", col(\"survived\").alias(\"label\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469523d",
   "metadata": {},
   "source": [
    "# Separar conjuntos en Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cf194bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos (80% entrenamiento, 20% prueba)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a9d12",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2ebee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "rf_predictions = rf_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "834e5307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä M√âTRICAS DEL MODELO RANDOM FOREST:\n",
      "Accuracy  : 0.743\n",
      "Precision : 0.741\n",
      "Recall    : 0.743\n",
      "F1 Score  : 0.742\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "f1 = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(\"üìä M√âTRICAS DEL MODELO RANDOM FOREST:\")\n",
    "print(f\"Accuracy  : {accuracy:.3f}\")\n",
    "print(f\"Precision : {precision:.3f}\")\n",
    "print(f\"Recall    : {recall:.3f}\")\n",
    "print(f\"F1 Score  : {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa8181ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|    1|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    1|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    1|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "|       0.0|    0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicciones = rf_model.transform(test_data)\n",
    "# Mostrar primeras 20 comparaciones entre valor real y predicho\n",
    "predicciones.select(\"prediction\", \"label\").show(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97254bd9",
   "metadata": {},
   "source": [
    "# Realizar predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b01c052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------------+\n",
      "|prediction|probability                             |\n",
      "+----------+----------------------------------------+\n",
      "|0.0       |[0.7667891633059346,0.23321083669406548]|\n",
      "+----------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# CREAR NUEVO PASAJERO YA INDEXADO\n",
    "nuevo_pasajero = spark.createDataFrame([\n",
    "    Row(\n",
    "        pclass=3,\n",
    "        sex_index=0.0,   # 1.0 para 'male', 0.0 para 'female' \n",
    "        age=25.0,\n",
    "        sibsp=0,\n",
    "        parch=0,\n",
    "        fare=100.25,\n",
    "        embarked_index=0.0,  # 0.0 para 'S', 1.0 para 'C', 2.0 para 'Q' \n",
    "        body=0\n",
    "    )\n",
    "])\n",
    "\n",
    "# USAR ASSEMBLER PARA ARMAR FEATURES\n",
    "nuevo_pasajero = assembler.transform(nuevo_pasajero)\n",
    "\n",
    "# PREDICCI√ìN\n",
    "prediccion_nuevo = rf_model.transform(nuevo_pasajero)\n",
    "\n",
    "# MOSTRAR RESULTADO\n",
    "prediccion_nuevo.select(\"prediction\", \"probability\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacb064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
